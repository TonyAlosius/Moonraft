{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Here, I have implemented a product similarity search functionality using TF-IDF vectorization and cosine similarity. The process involved reading data from CSV files, preprocessing the text data by removing stopwords and punctuation, calculating the cosine similarity between a query and a list of products, and finally, returning a list of ***similar products based on a specified threshold***. The code utilized libraries such as NLTK, scikit-learn, and CSV for data processing, vectorization, and similarity calculation.\n",
        "\n",
        "1. amazon_data = ***fetch_data***('/content/drive/MyDrive/ColabNotebooks/amazon.csv', 3)\n",
        "2. amazon_data = ***preprocess_data***(amazon_data)\n",
        "3. Repeat ***Step 1*** and ***Step 2*** for all the datasets\n",
        "4. similar_products_amazon = ***search_similar_products***(query, amazon_data, threshold)\n",
        "5. similar_products_currys = ***search_similar_products***(query, currys_data, threshold)\n"
      ],
      "metadata": {
        "id": "EIZLKi_NHyXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. The code mounts Google Drive to access the required CSV files"
      ],
      "metadata": {
        "id": "y96nO_VPxNhs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ4XhMoSX4dk",
        "outputId": "945d0d50-018a-4fef-d8f0-aedcbe984574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Import the Necessary Libraries"
      ],
      "metadata": {
        "id": "5AAoJdPXxaO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. TfidfVectorizer - the TF-IDF vectorizer is used to convert the textual data from the Lewis, Amazon and Currys datasets into numerical feature vectors. Specifically, the TF-IDF vectorizer is applied to the product names in the datasets.\n",
        "\n",
        "2. cosine_similarity - Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space. It calculates the cosine of the angle between the two vectors and determines how similar they are based on their orientations."
      ],
      "metadata": {
        "id": "cdZ03O_58373"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "DlhPGzu1cBgK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Fetch the Product Name out of the data"
      ],
      "metadata": {
        "id": "bSCKlsuExlCJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. The fetch_data function is responsible for extracting data from a CSV file. It takes the file path (file_route) and the Product name of the column (feature) from which the data needs to be extracted.\n",
        "\n",
        "2. It opens the CSV file and creates a CSV reader object to iterate over the rows. For each row, it accesses the value in the specified column (row[feature]) and appends it to the data list.\n",
        "\n",
        "3. Finally, the function returns the data list containing the extracted data from the CSV file."
      ],
      "metadata": {
        "id": "yzETz3P2_kwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_data(file_route, feature):\n",
        "    data = []\n",
        "    with open(file_route, 'r', encoding='utf-8') as file_name:\n",
        "        data_file = csv.reader(file_name)\n",
        "        for row in data_file:\n",
        "            # Appends the product names onto the data list\n",
        "            data.append(row[feature])\n",
        "    return data"
      ],
      "metadata": {
        "id": "IQifraJIf2Of"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Preprocess the Product Names using NLTK Toolkit"
      ],
      "metadata": {
        "id": "T-GxNxOHxrzN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The preprocess_data function takes a list of product names from the scraped data as input and performs text preprocessing tasks, including tokenization, removal of stopwords and punctuation, and joining tokens back into a preprocessed string. It returns a list of preprocessed text for each input element."
      ],
      "metadata": {
        "id": "fWMMN6CzA0Ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def preprocess_data(data):\n",
        "    nltk.download('stopwords')\n",
        "    nltk.download('punkt')\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    punctuation = set(string.punctuation)\n",
        "    preprocessed_data = []\n",
        "    for row in data:\n",
        "        tokens = word_tokenize(row)\n",
        "        tokens = [token.lower() for token in tokens if token.lower() not in stop_words and token not in punctuation]\n",
        "        preprocessed_row = ' '.join(tokens)\n",
        "        preprocessed_data.append(preprocessed_row)\n",
        "    return preprocessed_data\n"
      ],
      "metadata": {
        "id": "MtBQWetggoca"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Workbox of the above function"
      ],
      "metadata": {
        "id": "TXdZrsmxI3TG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ### NLTK ToolKit Workbox ###\n",
        "# nltk.download('stopwords')\n",
        "# nltk.download('punkt')\n",
        "# stop_words = set(stopwords.words('english'))\n",
        "# punctuation = set(string.punctuation)\n",
        "# # print(stop_words)\n",
        "# # print(punctuation)\n",
        "# for row in currys_data:\n",
        "#   preprocessed_data = []\n",
        "#   tokens = word_tokenize(row)\n",
        "#   # print(tokens)\n",
        "#   tokens = [token.lower() for token in tokens if token.lower() not in stop_words and token not in punctuation]\n",
        "#   preprocessed_row = ' '.join(tokens)\n",
        "#   # print(preprocessed_row)\n",
        "#   preprocessed_data.append(preprocessed_row)\n",
        "#   # print(preprocessed_data)\n",
        "# print(tfidf_matrix[:-1].shape)\n",
        "# print(tfidf_matrix[-1].shape)"
      ],
      "metadata": {
        "id": "QLH8QNSFc36j"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Calculate the Similarity Score"
      ],
      "metadata": {
        "id": "lmJp6KydyA3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The calculate_similarity function uses a TfidfVectorizer to convert text data of product name searched for and the list of product lists into TF-IDF vectors. It then calculates the cosine similarity between the query and each product, returning the similarity scores."
      ],
      "metadata": {
        "id": "J7kT6oqhCFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_similarity(searched_prod_name, products):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(products + [searched_prod_name])\n",
        "    similarity_scores = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])\n",
        "    return similarity_scores[0]"
      ],
      "metadata": {
        "id": "-MGcVKlZd4NR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Workbox of the above function"
      ],
      "metadata": {
        "id": "KHRRG3T0JGe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ### Cosine Similarity Workbox ###\n",
        "# query = john_lewis_data[21]\n",
        "# products = currys_data\n",
        "# vectorizer = TfidfVectorizer()\n",
        "# tfidf_matrix = vectorizer.fit_transform(products + [query])\n",
        "# print(tfidf_matrix)\n",
        "# print(tfidf_matrix.shape)\n",
        "# print(products + [query])\n",
        "# feature_names = vectorizer.get_feature_names_out()\n",
        "# for row, col in zip(*tfidf_matrix.nonzero()):\n",
        "#     word = feature_names[col]\n",
        "#     tfidf_value = tfidf_matrix[row, col]\n",
        "#     # print(f\"Row: {row}, Col: {col}, Word: {word}, TF-IDF Value: {tfidf_value}\")\n",
        "# similarity_scores = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])\n",
        "# print(similarity_scores)\n",
        "# print(similarity_scores.shape)\n",
        "# print(similarity_scores[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnu5HCpvJFX0",
        "outputId": "05ee440a-fa16-4021-e577-ebd8c919d593"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pdp-grid-product-name', 'tower freedom 13-piece non-stick pan set graphite', 'swan retro 5-piece non-stick pan set green', 'swan retro swps5020bn 5-piece non-stick pan set black', 'durastone k451gr 7-piece non-stick pan set grey', 'tower cerastone t81276 5-piece non-stick pan set graphite', 'swan retro 5-piece non-stick pan set blue', 'swan retro 2-piece non-stick frying pan set green', 'swan retro swps5020rn 5-piece non-stick pan set red', 'russell hobbs opulence rh01179eu 5-piece pan set blue', 'tower cerastone t81284 4-piece non-stick pan set graphite', 'cermalon k311cp 5-piece non-stick pan set copper', 'tefal jamie oliver quick easy 2-piece non-stick frying pan set stainless steel', 'russell hobbs classic collection bw06572eu7 5-piece pan set silver', 'durastone professional k460bk 7-piece non-stick pan set black', 'tefal jamie oliver quick easy e303s444 4-piece non-stick pan set stainless steel', 'durastone professional k461bk 24 cm non-stick casserole frying pan black', 'russell hobbs stackable rh01840eu7 4-piece non-stick pan set black', 'cermalon k436bp 5-piece non-stick pan set pink', 'cermalon k438bl 5-piece non-stick pan set blue', 'cermalon k462gr 6-piece non-stick pan set black silver', 'john lewis classic stainless steel non-stick frying pan 20cm']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "x_uTEHvcJE-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Search the Similar Products based on Similarity score"
      ],
      "metadata": {
        "id": "19rjbIgxyJYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The search_similar_products function takes a query, a list of products, and a threshold as input. It calculates the similarity scores between the query and each product using the calculate_similarity function. Then, it filters the products based on the threshold and returns a list of similar products."
      ],
      "metadata": {
        "id": "FQLvH89XKfJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_similar_products(searched_prod_name, products, threshold):\n",
        "    similarity_scores = calculate_similarity(searched_prod_name, products)\n",
        "    similar_products = []\n",
        "    for i, score in enumerate(similarity_scores):\n",
        "        if score >= threshold:\n",
        "            similar_products.append(products[i])\n",
        "    return similar_products"
      ],
      "metadata": {
        "id": "ceL_UcPCd6zG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Fetch and Preprocess the data"
      ],
      "metadata": {
        "id": "frt2PGDYyZaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "amazon_data = fetch_data('/content/drive/MyDrive/Colab Notebooks/amazon.csv', 3)\n",
        "amazon_data = amazon_data[1:]\n",
        "amazon_data = preprocess_data(amazon_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TC4JLCSqd-4X",
        "outputId": "e8be422e-59ec-4f7c-9a36-494551713487"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "currys_data = fetch_data('/content/drive/MyDrive/Colab Notebooks/currys.csv', 2)\n",
        "currys_data = currys_data[1:]\n",
        "currys_data = preprocess_data(currys_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvWYP0Dalrqx",
        "outputId": "70af6198-4c30-4310-bcca-45daf9c25b53"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "john_lewis_data = fetch_data('/content/drive/MyDrive/Colab Notebooks/johnlewis.csv', 2)\n",
        "john_lewis_data = john_lewis_data[1:]\n",
        "john_lewis_data = preprocess_data(john_lewis_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ys24s-zl0y1",
        "outputId": "f78da9bf-fa68-4409-f489-f0dcde6ffd7f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "############## Select the Product name to search #########################"
      ],
      "metadata": {
        "id": "gouzaPuJz31P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "searched_prod_name = john_lewis_data[21]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MtD8XWZ7zQPh",
        "outputId": "2c8b073d-4f29-4ac1-9240-ab927e7b81b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'john lewis classic stainless steel non-stick frying pan 20cm'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Search the product name and fetch the similar products from other two sites"
      ],
      "metadata": {
        "id": "c0gGsVfWye0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "searched_prod_name = john_lewis_data[21]\n",
        "threshold = 0.3\n",
        "\n",
        "similar_products_amazon = search_similar_products(searched_prod_name, amazon_data, threshold)\n",
        "similar_products_currys = search_similar_products(searched_prod_name, currys_data, threshold)\n",
        "\n",
        "print(\"Similar products in Amazon:\")\n",
        "for product in similar_products_amazon:\n",
        "    print(product)\n",
        "\n",
        "print(\"\\nSimilar products in Currys:\")\n",
        "for product in similar_products_currys:\n",
        "    print(product)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-52sjrrUmLMI",
        "outputId": "6d536779-49a5-48f7-e425-987524b18daf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar products in Amazon:\n",
            "\n",
            "Similar products in Currys:\n",
            "tefal jamie oliver quick easy 2-piece non-stick frying pan set stainless steel\n"
          ]
        }
      ]
    }
  ]
}